{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模块测试 梯度测试\n",
    "from turtle import forward\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "\n",
    "vgg = nn.Sequential(\n",
    "    nn.Conv2d(3, 3, (1, 1)),\n",
    "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "    nn.Conv2d(3, 64, (3, 3)),\n",
    "    nn.ReLU(),  # relu1-1\n",
    "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "    nn.Conv2d(64, 64, (3, 3)),\n",
    "    nn.ReLU(),  # relu1-2\n",
    "    nn.MaxPool2d((2, 2), (2, 2), (0, 0), ceil_mode=True),\n",
    "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "    nn.Conv2d(64, 128, (3, 3)),\n",
    "    nn.ReLU(),  # relu2-1\n",
    "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "    nn.Conv2d(128, 128, (3, 3)),\n",
    "    nn.ReLU(),  # relu2-2\n",
    "    nn.MaxPool2d((2, 2), (2, 2), (0, 0), ceil_mode=True),\n",
    "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "    nn.Conv2d(128, 256, (3, 3)),\n",
    "    nn.ReLU(),  # relu3-1\n",
    "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "    nn.Conv2d(256, 256, (3, 3)),\n",
    "    nn.ReLU(),  # relu3-2\n",
    "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "    nn.Conv2d(256, 256, (3, 3)),\n",
    "    nn.ReLU(),  # relu3-3\n",
    "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "    nn.Conv2d(256, 256, (3, 3)),\n",
    "    nn.ReLU(),  # relu3-4\n",
    "    nn.MaxPool2d((2, 2), (2, 2), (0, 0), ceil_mode=True),\n",
    "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "    nn.Conv2d(256, 512, (3, 3)),\n",
    "    nn.ReLU(),  # relu4-1, this is the last layer used\n",
    "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "    nn.Conv2d(512, 512, (3, 3)),\n",
    "    nn.ReLU(),  # relu4-2\n",
    "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "    nn.Conv2d(512, 512, (3, 3)),\n",
    "    nn.ReLU(),  # relu4-3\n",
    "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "    nn.Conv2d(512, 512, (3, 3)),\n",
    "    nn.ReLU(),  # relu4-4\n",
    "    nn.MaxPool2d((2, 2), (2, 2), (0, 0), ceil_mode=True),\n",
    "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "    nn.Conv2d(512, 512, (3, 3)),\n",
    "    nn.ReLU(),  # relu5-1\n",
    "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "    nn.Conv2d(512, 512, (3, 3)),\n",
    "    nn.ReLU(),  # relu5-2\n",
    "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "    nn.Conv2d(512, 512, (3, 3)),\n",
    "    nn.ReLU(),  # relu5-3\n",
    "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "    nn.Conv2d(512, 512, (3, 3)),\n",
    "    nn.ReLU()  # relu5-4\n",
    ")\n",
    "\n",
    "def calc_mean_std(feat, eps=1e-5):\n",
    "    # eps is a small value added to the variance to avoid divide-by-zero.\n",
    "    size = feat.size()\n",
    "    # assert (len(size) == 4)\n",
    "    other = size[:-2]\n",
    "    feat_var = feat.reshape(*other, -1).var(dim=-1) + eps\n",
    "    feat_std = feat_var.sqrt().reshape(*other, 1, 1)\n",
    "    feat_mean = feat.reshape(*other, -1).mean(dim=-1).reshape(*other, 1, 1)\n",
    "    return feat_mean, feat_std\n",
    "\n",
    "\n",
    "def adaIN(content_feat, style_feat):\n",
    "    assert (content_feat.size()[:-2] == style_feat.size()[:-2])\n",
    "    size = content_feat.size()\n",
    "    style_mean, style_std = calc_mean_std(style_feat)\n",
    "    content_mean, content_std = calc_mean_std(content_feat)\n",
    "\n",
    "    normalized_feat = (content_feat - content_mean) / content_std\n",
    "    return normalized_feat * style_std + style_mean\n",
    "\n",
    "def oldblock_adaIN(content_feat, style_feat, block = 16):\n",
    "    assert (content_feat.size()[:-2] == style_feat.size()[:-2])\n",
    "    assert content_feat.size()[-1] % block == 0\n",
    "    assert content_feat.size()[-2] % block == 0\n",
    "    size = content_feat.size()\n",
    "    N, C, H, W = size\n",
    "    newC = C * size[-1] * size[-2] / block / block\n",
    "    return adaIN(content_feat.reshape(N,C,H // block, block, W // block, block).transpose(3,4),\n",
    "                                        style_feat.reshape(N,C,H // block, block, W // block, block).transpose(3,4)\n",
    "                                        ).transpose(3,4).reshape(size)\n",
    "\n",
    "def block_adaIN(content_feat, style_feat, block = 16):\n",
    "    assert (content_feat.size()[:-2] == style_feat.size()[:-2])\n",
    "    content_feat = blockzation(content_feat, block)\n",
    "    style_feat = blockzation(style_feat, block)\n",
    "    return  unblockzation(adaIN(content_feat, style_feat))\n",
    "\n",
    "def blockzation(feat, block = 16):\n",
    "    H, W = feat.size()[-2:]\n",
    "    assert H % block == 0\n",
    "    assert W % block == 0\n",
    "    size = feat.size()[:-2]\n",
    "    feat = feat.reshape(*size, H // block, block, W // block, block).transpose(-2, -3)\n",
    "    return feat\n",
    "\n",
    "def unblockzation(feat):\n",
    "    size = feat.size()\n",
    "    H = size[-4] * size[-2]\n",
    "    W = size[-3] * size[-1]\n",
    "    size = size[:-4]\n",
    "    return feat.transpose(-2, -3).reshape(*size, H, W)\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, encoder, level = 1):\n",
    "        super(Net, self).__init__()\n",
    "        enc_layers = list(encoder.children())[:44]\n",
    "        self.enc_1 = nn.Sequential(*enc_layers[:4])  # input -> relu1_1\n",
    "        self.enc_2 = nn.Sequential(*enc_layers[4:11])  # relu1_1 -> relu2_1\n",
    "        self.enc_3 = nn.Sequential(*enc_layers[11:18])  # relu2_1 -> relu3_1\n",
    "        self.enc_4 = nn.Sequential(*enc_layers[18:31])  # relu3_1 -> relu4_1\n",
    "        self.enc_5 = nn.Sequential(*enc_layers[31:44])  # relu4_1 -> relu5_1\n",
    "\n",
    "        self.level = level\n",
    "        # fix the encoder\n",
    "        for name in ['enc_1', 'enc_2', 'enc_3', 'enc_4', 'enc_5']:\n",
    "            for param in getattr(self, name).parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "    def encode_with_intermediate(self, input):\n",
    "        results = [input]\n",
    "        for i in range(4):\n",
    "            func = getattr(self, 'enc_{:d}'.format(i + 1))\n",
    "            results.append(func(results[-1]))\n",
    "        return results[1:]\n",
    "    \n",
    "    def encode_with_level(self, input, level):\n",
    "        for i in range(level):\n",
    "            func = getattr(self, 'enc_{:d}'.format(i + 1))\n",
    "            input = func(input)\n",
    "        return input\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.encode_with_level(x, self.level)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "def dynamic_adj_add(vec1, vec2):\n",
    "    assert vec1.shape == vec2.shape\n",
    "    shape = vec1.shape\n",
    "    vec1 = vec1.view(shape[0], -1)\n",
    "    vec2 = vec2.view(shape[0], -1)\n",
    "    v1v1 = (vec1 * vec1).mean(dim = 1)\n",
    "    v1v2 = (vec1 * vec2).mean(dim = 1)\n",
    "    v2v2 = (vec2 * vec2).mean(dim = 1)\n",
    "    gamma = min_norm_element_from2(v1v1, v1v2, v2v2).view(shape[0], 1)\n",
    "    return (gamma  * vec1 + (1 - gamma) * vec2).view(shape)\n",
    "\n",
    "def min_norm_element_from2(v1v1, v1v2, v2v2):\n",
    "        divide = v1v1+v2v2 - 2*v1v2\n",
    "        gamma = -1.0 * ( (v1v2 - v2v2) / (v1v1+v2v2 - 2*v1v2))\n",
    "        gamma = torch.where(torch.isnan(gamma), torch.full_like(gamma, 1), gamma)\n",
    "        return gamma.clamp(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(64,2)\n",
    "y = torch.ones(64,2)\n",
    "y[:,0] = .05\n",
    "\n",
    "print(dynamic_adj_add(x,x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-9.1397e-05, grad_fn=<MeanBackward0>)\n",
      "tensor(20983.5996, grad_fn=<CopyBackwards>)\n",
      "tensor(528136.9375, grad_fn=<CopyBackwards>)\n",
      "tensor(0.0032, grad_fn=<MeanBackward0>)\n",
      "tensor(21011.6348, grad_fn=<CopyBackwards>)\n",
      "tensor(532531.9375, grad_fn=<CopyBackwards>)\n",
      "tensor(0.0068, grad_fn=<MeanBackward0>)\n",
      "tensor(21041.2070, grad_fn=<CopyBackwards>)\n",
      "tensor(538549.3750, grad_fn=<CopyBackwards>)\n",
      "tensor(0.0105, grad_fn=<MeanBackward0>)\n",
      "tensor(21070.6367, grad_fn=<CopyBackwards>)\n",
      "tensor(545544.9375, grad_fn=<CopyBackwards>)\n",
      "tensor(0.0144, grad_fn=<MeanBackward0>)\n",
      "tensor(21098.6582, grad_fn=<CopyBackwards>)\n",
      "tensor(552861.8125, grad_fn=<CopyBackwards>)\n",
      "tensor(0.0185, grad_fn=<MeanBackward0>)\n",
      "tensor(21124.4336, grad_fn=<CopyBackwards>)\n",
      "tensor(560169.1250, grad_fn=<CopyBackwards>)\n",
      "tensor(0.0228, grad_fn=<MeanBackward0>)\n",
      "tensor(21147.4727, grad_fn=<CopyBackwards>)\n",
      "tensor(567303.5000, grad_fn=<CopyBackwards>)\n",
      "tensor(0.0271, grad_fn=<MeanBackward0>)\n",
      "tensor(21167.4727, grad_fn=<CopyBackwards>)\n",
      "tensor(574044.3750, grad_fn=<CopyBackwards>)\n",
      "tensor(0.0316, grad_fn=<MeanBackward0>)\n",
      "tensor(21184.3340, grad_fn=<CopyBackwards>)\n",
      "tensor(580247.3125, grad_fn=<CopyBackwards>)\n",
      "tensor(0.0362, grad_fn=<MeanBackward0>)\n",
      "tensor(21198.1680, grad_fn=<CopyBackwards>)\n",
      "tensor(585878.1875, grad_fn=<CopyBackwards>)\n",
      "tensor(0.0408, grad_fn=<MeanBackward0>)\n",
      "tensor(21209.1406, grad_fn=<CopyBackwards>)\n",
      "tensor(590867.7500, grad_fn=<CopyBackwards>)\n",
      "tensor(0.0455, grad_fn=<MeanBackward0>)\n",
      "tensor(21217.3887, grad_fn=<CopyBackwards>)\n",
      "tensor(595355.8125, grad_fn=<CopyBackwards>)\n",
      "tensor(0.0502, grad_fn=<MeanBackward0>)\n",
      "tensor(21223.1836, grad_fn=<CopyBackwards>)\n",
      "tensor(599333.8125, grad_fn=<CopyBackwards>)\n",
      "tensor(0.0550, grad_fn=<MeanBackward0>)\n",
      "tensor(21226.7266, grad_fn=<CopyBackwards>)\n",
      "tensor(602845.1875, grad_fn=<CopyBackwards>)\n",
      "tensor(0.0598, grad_fn=<MeanBackward0>)\n",
      "tensor(21228.2734, grad_fn=<CopyBackwards>)\n",
      "tensor(605946.1250, grad_fn=<CopyBackwards>)\n",
      "tensor(0.0647, grad_fn=<MeanBackward0>)\n",
      "tensor(21228.0137, grad_fn=<CopyBackwards>)\n",
      "tensor(608669.0625, grad_fn=<CopyBackwards>)\n",
      "tensor(0.0696, grad_fn=<MeanBackward0>)\n",
      "tensor(21226.1641, grad_fn=<CopyBackwards>)\n",
      "tensor(611049.4375, grad_fn=<CopyBackwards>)\n",
      "tensor(0.0745, grad_fn=<MeanBackward0>)\n",
      "tensor(21222.8672, grad_fn=<CopyBackwards>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/sunsk/Projects/ilvr_adm/test.ipynb Cell 2\u001b[0m in \u001b[0;36m<cell line: 43>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://localhost:23434/home/sunsk/Projects/ilvr_adm/test.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=88'>89</a>\u001b[0m     blocked_x_in \u001b[39m=\u001b[39m normalized_blocked_x \u001b[39m*\u001b[39m std \u001b[39m+\u001b[39m mean\n\u001b[1;32m     <a href='vscode-notebook-cell://localhost:23434/home/sunsk/Projects/ilvr_adm/test.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=89'>90</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> <a href='vscode-notebook-cell://localhost:23434/home/sunsk/Projects/ilvr_adm/test.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=90'>91</a>\u001b[0m     grad \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mgrad(loss\u001b[39m.\u001b[39;49msum(), blocked_x_in)[\u001b[39m0\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell://localhost:23434/home/sunsk/Projects/ilvr_adm/test.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=91'>92</a>\u001b[0m     blocked_x_in \u001b[39m=\u001b[39m blocked_x_in \u001b[39m-\u001b[39m iterate_lr \u001b[39m*\u001b[39m grad\n\u001b[1;32m     <a href='vscode-notebook-cell://localhost:23434/home/sunsk/Projects/ilvr_adm/test.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=92'>93</a>\u001b[0m x_feat \u001b[39m=\u001b[39m net(unblockzation(blocked_x_in))\n",
      "File \u001b[0;32m~/anaconda3/envs/sde/lib/python3.8/site-packages/torch/autograd/__init__.py:226\u001b[0m, in \u001b[0;36mgrad\u001b[0;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused)\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[39mif\u001b[39;00m retain_graph \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    224\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m--> 226\u001b[0m \u001b[39mreturn\u001b[39;00m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(\n\u001b[1;32m    227\u001b[0m     outputs, grad_outputs_, retain_graph, create_graph,\n\u001b[1;32m    228\u001b[0m     inputs, allow_unused, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 待测试方案\n",
    "# 以下每行的排列组合\n",
    "##  是否使用blockadain初始化\n",
    "##  MSE or KL \n",
    "##  仅仅调节std和mean (blockadain level shape (batch, channel, area, area, 1, 1))还是直接调节feature map\n",
    "###  MSE with std&mean 是直接std和mean分别的MSE\n",
    "##  迭代次数 (考虑是用adam之类的优化器)\n",
    "##  迭代的学习率\n",
    "##  差分值的系数 \n",
    "##  vgg网络深度\n",
    "\n",
    "# 一个 optimization\n",
    "# 此外还需要实现加噪信号的block 均值和方差的计算(推一推公式)\n",
    "# basic\n",
    "# x_t = a * x + b * z\n",
    "# E(x_t) = a * E(x)\n",
    "# Var(x_t) = a^2 * var(x) + b^2 \n",
    "# 计算好ref image的block level的均值和方差之后, 可以通过计算的方式直接得到需要的均值和方差\n",
    "\n",
    "####### things to adjust\n",
    "\n",
    "### 梯度方案很容易偏色\n",
    "### 仅仅迁移均值方差细节迁移不到位\n",
    "### 两种方案合在一起, 先做neural feature的细节transfer, 再做image level的blockAdain\n",
    "init_with_blockadain = True\n",
    "# MSE is the MSE with adained feature map, While KL is the KL divergence of two distribulation, \n",
    "# but it has the same best optimization point with L2 distance between means, and between vars, further try to use multi task opt methods\n",
    "losstype = \"KL\" # \"MSE\" or \"KL\"\n",
    "# when use affine, the image level features only changes as affine\n",
    "affine = False # keep image features affine\n",
    "iterate_times = 30000 # the iterate times\n",
    "iterate_lr = 1e-1 / 64 # the iterate learning rate \n",
    "difference_std = 7 # the std of difference / the std of the score\n",
    "vggdeep = 1 # the feature extractor depth 1/2/3\n",
    "area = 16 # in 1d how many part to divide 8/16/32\n",
    "\n",
    "vgg.load_state_dict(torch.load(\"/home/sunsk/Models/vgg/vgg_normalised.pth\"))\n",
    "\n",
    "net = Net(vgg, level = vggdeep)\n",
    "net.eval()\n",
    "x = torch.randn(64,3,256,256) # source \n",
    "y = torch.randn(64,3,256,256)*3 + 5 # target features\n",
    "H, W = x.shape[-2:]\n",
    "blocked_x = blockzation(x, block = H // area)\n",
    "blocked_y = blockzation(y, block= H // area)\n",
    "# prepare features to optimization\n",
    "with torch.enable_grad():\n",
    "    if affine:\n",
    "        blocked_x_mean, blocked_x_std = calc_mean_std(blocked_x) # [batchsize, channel, area, area, 1, 1]\n",
    "        blocked_y_mean, blocked_y_std = calc_mean_std(blocked_y) # can be caltulated before\n",
    "        if init_with_blockadain:\n",
    "            mean = blocked_y_mean.detach().requires_grad_(True) # need to be updated to block level\n",
    "            std = blocked_y_std.detach().requires_grad_(True)\n",
    "        else:\n",
    "            mean = blocked_x_mean.detach().requires_grad_(True)\n",
    "            std = blocked_x_std.detach().requires_grad_(True)\n",
    "        \n",
    "        normalized_blocked_x = (blocked_x - blocked_x_mean) / blocked_x_std\n",
    "        blocked_x_in = normalized_blocked_x * std + mean\n",
    "    else:\n",
    "        if init_with_blockadain:\n",
    "            blocked_x_in = adaIN(blocked_x, blocked_y).detach().requires_grad_(True)\n",
    "        else:\n",
    "            blocked_x_in = blocked_x.detach().requires_grad_(True)\n",
    "\n",
    "    x_feat = net(unblockzation(blocked_x_in))\n",
    "    y_feat = net(y)\n",
    "    H, W = x_feat.shape[-2:]\n",
    "    blocked_x_feat = blockzation(x_feat,block = H // area)\n",
    "    blocked_y_feat = blockzation(y_feat,block = H // area)\n",
    "\n",
    "    blocked_y_feat_mean, blocked_y_feat_std = calc_mean_std(blocked_y_feat)\n",
    "\n",
    "    for _ in range(iterate_times):\n",
    "        print(blocked_x_in.mean())\n",
    "        print((blocked_x_in - blocked_y).norm())\n",
    "        if losstype == \"MSE\":\n",
    "            blocked_target = adaIN(blocked_x_feat, blocked_y_feat)\n",
    "            loss = (blocked_x_feat - blocked_target) ** 2\n",
    "        # elif losstype == \"KL\":\n",
    "        else:\n",
    "            blocked_x_feat_mean, blocked_x_feat_std = calc_mean_std(blocked_x_feat)\n",
    "            # original but not stable loss\n",
    "            # loss = x_var / y_var + (x_mean - y_mean) / y_var - torch.log(x_var / y_var) - 1\n",
    "            # stable loss\n",
    "            loss = (blocked_x_feat_mean - blocked_y_feat_mean) ** 2 + (blocked_x_feat_std - blocked_y_feat_std) ** 2\n",
    "\n",
    "        if affine:\n",
    "            grad1 = torch.autograd.grad(loss.sum(), std, retain_graph= True)[0]\n",
    "            grad2 = torch.autograd.grad(loss.sum(), mean)[0]\n",
    "            std = std - iterate_lr * grad1\n",
    "            mean = mean - iterate_lr * grad2\n",
    "            blocked_x_in = normalized_blocked_x * std + mean\n",
    "        else:\n",
    "            grad = torch.autograd.grad(loss.sum(), blocked_x_in)[0]\n",
    "            blocked_x_in = blocked_x_in - iterate_lr * grad\n",
    "        x_feat = net(unblockzation(blocked_x_in))\n",
    "        blocked_x_feat = blockzation(x_feat,block = H // area)\n",
    "        print((blocked_x_feat - blocked_y_feat).norm())\n",
    "        # target = block_adaIN(x_feat, y_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(2, 3, 64, 64)\n",
    "y = torch.ones(2, 3, 64, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "print(block_adaIN(x, y).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1000])\n"
     ]
    }
   ],
   "source": [
    "### grad 测试\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from torchvision import models\n",
    "\n",
    "func = models.resnet101(pretrained=True)\n",
    "data = torch.rand(64,3,64,64)\n",
    "func.eval()\n",
    "print(func(data).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(811.0899)\n",
      "811.0912\n"
     ]
    }
   ],
   "source": [
    "with torch.enable_grad():\n",
    "    x_in = data.detach().requires_grad_(True)\n",
    "    logits = func(x_in).view(64,-1).sum(dim=-1)\n",
    "    print(torch.autograd.grad(logits.sum(), x_in)[0].norm())\n",
    "    print(64*12.6733)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as th\n",
    "def dynamic_adj_add(vec1, vec2):\n",
    "    # print(vec1.shape)\n",
    "    assert vec1.shape == vec2.shape\n",
    "    shape = vec1.shape\n",
    "    vec1 = vec1.view(shape[0], -1)\n",
    "    vec2 = vec2.view(shape[0], -1)\n",
    "    v1v1 = (vec1 * vec1).mean(dim = 1)\n",
    "    v1v2 = (vec1 * vec2).mean(dim = 1)\n",
    "    v2v2 = (vec2 * vec2).mean(dim = 1)\n",
    "    gamma = min_norm_element_from2(v1v1, v1v2, v2v2).view(shape[0], 1)\n",
    "    coef = ((1 - gamma)/gamma).clamp(0,30)\n",
    "    coef = th.where(th.isnan(coef), th.full_like(coef, 0), coef)\n",
    "    # return (gamma * vec1 + (1 - gamma) * vec2).view(shape)\n",
    "    return (vec1 + coef * vec2).view(shape)\n",
    "\n",
    "def min_norm_element_from2(v1v1, v1v2, v2v2):\n",
    "    divide = v1v1+v2v2 - 2*v1v2\n",
    "    gamma = (v2v2 - v1v2) / divide\n",
    "    gamma = th.where(th.isnan(gamma), th.full_like(gamma, 0), gamma)\n",
    "    return gamma.clamp(0, 1)\n",
    "\n",
    "# veclist shape: [batch, number, others]\n",
    "# 方案一, 提取跟diffuison 方向垂直的分量, 将这些分量想办法dynamic化\n",
    "# 方案二, 将当前的方案暴力拓展到三个变量的情况\n",
    "def frank_wolfe_solver(veclist, ep = 1e-4, maxnum = 20):\n",
    "    shape = veclist.shape\n",
    "    veclist = veclist.view(shape[0], shape[1], -1) # shape [B, N, O]\n",
    "    M = veclist @ veclist.transpose(1,2) # shape [B, N, N]\n",
    "    a = (th.ones(shape[:2]) / shape[1]).unsqueeze(1).to(veclist.device) # shape [B, 1, N]\n",
    "    for _ in range(maxnum):\n",
    "        minrank = th.argmin(a @ M, dim = 2) # shape [B, 1]\n",
    "        minonehot = th.zeros(shape[:2]).to(veclist.device).scatter_(1, minrank, 1).unsqueeze(1) # shape [B, 1, N]\n",
    "        gamma = min_norm_element_from2(minonehot @ M @ minonehot.transpose(1,2),minonehot @ M @ a.transpose(1,2), a @ M @ a.transpose(1,2)).reshape(-1, 1, 1)\n",
    "        # minvec = th.diagonal(veclist[:,minrank]).transpose(0,1)\n",
    "        a = (1-gamma)* a + gamma * minonehot\n",
    "        if th.abs(gamma).mean()< ep:\n",
    "            return a\n",
    "    return a\n",
    "\n",
    "veclist = th.rand(3,3,3,64,64).to(device=\"cuda\")\n",
    "a = frank_wolfe_solver(veclist)\n",
    "print(a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "torch.Size([64, 512, 32, 32])\n",
      "tensor(48.5318, grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "\n",
    "path = \"/home/sunsk/Models/resnet50/resnet50-19c8e357.pth\"\n",
    "resnet50 = models.resnet50(pretrained=False)\n",
    "resnet50.load_state_dict(torch.load(path))\n",
    "resnet50.eval()\n",
    "print(len(list(resnet50.children())))\n",
    "newmodel = torch.nn.Sequential(*(list(resnet50.children())[:6]))\n",
    "cos = torch.nn.CosineSimilarity(eps = 1e-6)\n",
    "batch = x.shape[0]\n",
    "x = torch.rand(64,3,256,256)\n",
    "y = torch.rand(64,3,256,256)\n",
    "xh = newmodel(x)\n",
    "yh = newmodel(y)\n",
    "cossimi = cos(xh, yh).mean() * batch\n",
    "print(xh.shape)\n",
    "print(cossimi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.7101],\n",
      "          [0.0259],\n",
      "          [0.5566]]]])\n",
      "tensor([[[[0.0000],\n",
      "          [0.0000],\n",
      "          [0.9167]]]])\n",
      "torch.Size([1, 1, 3, 1])\n",
      "1 1 3 1\n",
      "tensor([[[[0.7101],\n",
      "          [0.0259],\n",
      "          [0.0000]]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.rand(1, 1, 3, 1)\n",
    "y = torch.rand(1, 1, 3, 1)\n",
    "y[:,:,:2,:] = 0\n",
    "print(x)\n",
    "print(y)\n",
    "print(get_vertical_component(x, y, independdims=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00000.png\n",
      "00001.png\n",
      "00002.png\n",
      "00003.png\n",
      "00004.png\n",
      "00005.png\n",
      "00006.png\n",
      "00007.png\n",
      "00008.png\n",
      "00009.png\n",
      "00010.png\n",
      "00011.png\n",
      "00012.png\n",
      "00013.png\n",
      "00014.png\n",
      "00015.png\n",
      "00016.png\n",
      "00017.png\n",
      "00018.png\n",
      "00019.png\n",
      "00020.png\n",
      "00021.png\n",
      "00022.png\n",
      "00023.png\n",
      "00024.png\n",
      "00025.png\n",
      "00026.png\n",
      "00027.png\n",
      "00028.png\n",
      "00029.png\n",
      "00030.png\n",
      "00031.png\n",
      "00032.png\n",
      "00033.png\n",
      "00034.png\n",
      "00035.png\n",
      "00036.png\n",
      "00037.png\n",
      "00038.png\n",
      "00039.png\n",
      "00040.png\n",
      "00041.png\n",
      "00042.png\n",
      "00043.png\n",
      "00044.png\n",
      "00045.png\n",
      "00046.png\n",
      "00047.png\n",
      "00048.png\n",
      "00049.png\n",
      "00050.png\n",
      "00051.png\n",
      "00052.png\n",
      "00053.png\n",
      "00054.png\n",
      "00055.png\n",
      "00056.png\n",
      "00057.png\n",
      "00058.png\n",
      "00059.png\n",
      "00060.png\n",
      "00061.png\n",
      "00062.png\n",
      "00063.png\n",
      "00064.png\n",
      "00065.png\n",
      "00066.png\n",
      "00067.png\n",
      "00068.png\n",
      "00069.png\n",
      "00070.png\n",
      "00071.png\n",
      "00072.png\n",
      "00073.png\n",
      "00074.png\n",
      "00075.png\n",
      "00076.png\n",
      "00077.png\n",
      "00078.png\n",
      "00079.png\n",
      "00080.png\n",
      "00081.png\n",
      "00082.png\n",
      "00083.png\n",
      "00084.png\n",
      "00085.png\n",
      "00086.png\n",
      "00087.png\n",
      "00088.png\n",
      "00089.png\n",
      "00090.png\n",
      "00091.png\n",
      "00092.png\n",
      "00093.png\n",
      "00094.png\n",
      "00095.png\n",
      "00096.png\n",
      "00097.png\n",
      "00098.png\n",
      "00099.png\n",
      "00100.png\n",
      "00101.png\n",
      "00102.png\n",
      "00103.png\n",
      "00104.png\n",
      "00105.png\n",
      "00106.png\n",
      "00107.png\n",
      "00108.png\n",
      "00109.png\n",
      "00110.png\n",
      "00111.png\n",
      "00112.png\n",
      "00113.png\n",
      "00114.png\n",
      "00115.png\n",
      "00116.png\n",
      "00117.png\n",
      "00118.png\n",
      "00119.png\n",
      "00120.png\n",
      "00121.png\n",
      "00122.png\n",
      "00123.png\n",
      "00124.png\n",
      "00125.png\n",
      "00126.png\n",
      "00127.png\n",
      "00128.png\n",
      "00129.png\n",
      "00130.png\n",
      "00131.png\n",
      "00132.png\n",
      "00133.png\n",
      "00134.png\n",
      "00135.png\n",
      "00136.png\n",
      "00137.png\n",
      "00138.png\n",
      "00139.png\n",
      "00140.png\n",
      "00141.png\n",
      "00142.png\n",
      "00143.png\n",
      "00144.png\n",
      "00145.png\n",
      "00146.png\n",
      "00147.png\n",
      "00148.png\n",
      "00149.png\n",
      "00150.png\n",
      "00151.png\n",
      "00152.png\n",
      "00153.png\n",
      "00154.png\n",
      "00155.png\n",
      "00156.png\n",
      "00157.png\n",
      "00158.png\n",
      "00159.png\n",
      "00160.png\n",
      "00161.png\n",
      "00162.png\n",
      "00163.png\n",
      "00164.png\n",
      "00165.png\n",
      "00166.png\n",
      "00167.png\n",
      "00168.png\n",
      "00169.png\n",
      "00170.png\n",
      "00171.png\n",
      "00172.png\n",
      "00173.png\n",
      "00174.png\n",
      "00175.png\n",
      "00176.png\n",
      "00177.png\n",
      "00178.png\n",
      "00179.png\n",
      "00180.png\n",
      "00181.png\n",
      "00182.png\n",
      "00183.png\n",
      "00184.png\n",
      "00185.png\n",
      "00186.png\n",
      "00187.png\n",
      "00188.png\n",
      "00189.png\n",
      "00190.png\n",
      "00191.png\n",
      "00192.png\n",
      "00193.png\n",
      "00194.png\n",
      "00195.png\n",
      "00196.png\n",
      "00197.png\n",
      "00198.png\n",
      "00199.png\n",
      "00200.png\n",
      "00201.png\n",
      "00202.png\n",
      "00203.png\n",
      "00204.png\n",
      "00205.png\n",
      "00206.png\n",
      "00207.png\n",
      "00208.png\n",
      "00209.png\n",
      "00210.png\n",
      "00211.png\n",
      "00212.png\n",
      "00213.png\n",
      "00214.png\n",
      "00215.png\n",
      "00216.png\n",
      "00217.png\n",
      "00218.png\n",
      "00219.png\n",
      "00220.png\n",
      "00221.png\n",
      "00222.png\n",
      "00223.png\n",
      "00224.png\n",
      "00225.png\n",
      "00226.png\n",
      "00227.png\n",
      "00228.png\n",
      "00229.png\n",
      "00230.png\n",
      "00231.png\n",
      "00232.png\n",
      "00233.png\n",
      "00234.png\n",
      "00235.png\n",
      "00236.png\n",
      "00237.png\n",
      "00238.png\n",
      "00239.png\n",
      "00240.png\n",
      "00241.png\n",
      "00242.png\n",
      "00243.png\n",
      "00244.png\n",
      "00245.png\n",
      "00246.png\n",
      "00247.png\n",
      "00248.png\n",
      "00249.png\n",
      "00250.png\n",
      "00251.png\n",
      "00252.png\n",
      "00253.png\n",
      "00254.png\n",
      "00255.png\n",
      "00256.png\n",
      "00257.png\n",
      "00258.png\n",
      "00259.png\n",
      "00260.png\n",
      "00261.png\n",
      "00262.png\n",
      "00263.png\n",
      "00264.png\n",
      "00265.png\n",
      "00266.png\n",
      "00267.png\n",
      "00268.png\n",
      "00269.png\n",
      "00270.png\n",
      "00271.png\n",
      "00272.png\n",
      "00273.png\n",
      "00274.png\n",
      "00275.png\n",
      "00276.png\n",
      "00277.png\n",
      "00278.png\n",
      "00279.png\n",
      "00280.png\n",
      "00281.png\n",
      "00282.png\n",
      "00283.png\n",
      "00284.png\n",
      "00285.png\n",
      "00286.png\n",
      "00287.png\n",
      "00288.png\n",
      "00289.png\n",
      "00290.png\n",
      "00291.png\n",
      "00292.png\n",
      "00293.png\n",
      "00294.png\n",
      "00295.png\n",
      "00296.png\n",
      "00297.png\n",
      "00298.png\n",
      "00299.png\n",
      "00300.png\n",
      "00301.png\n",
      "00302.png\n",
      "00303.png\n",
      "00304.png\n",
      "00305.png\n",
      "00306.png\n",
      "00307.png\n",
      "00308.png\n",
      "00309.png\n",
      "00310.png\n",
      "00311.png\n",
      "00312.png\n",
      "00313.png\n",
      "00314.png\n",
      "00315.png\n",
      "00316.png\n",
      "00317.png\n",
      "00318.png\n",
      "00319.png\n",
      "00320.png\n",
      "00321.png\n",
      "00322.png\n",
      "00323.png\n",
      "00324.png\n",
      "00325.png\n",
      "00326.png\n",
      "00327.png\n",
      "00328.png\n",
      "00329.png\n",
      "00330.png\n",
      "00331.png\n",
      "00332.png\n",
      "00333.png\n",
      "00334.png\n",
      "00335.png\n",
      "00336.png\n",
      "00337.png\n",
      "00338.png\n",
      "00339.png\n",
      "00340.png\n",
      "00341.png\n",
      "00342.png\n",
      "00343.png\n",
      "00344.png\n",
      "00345.png\n",
      "00346.png\n",
      "00347.png\n",
      "00348.png\n",
      "00349.png\n",
      "00350.png\n",
      "00351.png\n",
      "00352.png\n",
      "00353.png\n",
      "00354.png\n",
      "00355.png\n",
      "00356.png\n",
      "00357.png\n",
      "00358.png\n",
      "00359.png\n",
      "00360.png\n",
      "00361.png\n",
      "00362.png\n",
      "00363.png\n",
      "00364.png\n",
      "00365.png\n",
      "00366.png\n",
      "00367.png\n",
      "00368.png\n",
      "00369.png\n",
      "00370.png\n",
      "00371.png\n",
      "00372.png\n",
      "00373.png\n",
      "00374.png\n",
      "00375.png\n",
      "00376.png\n",
      "00377.png\n",
      "00378.png\n",
      "00379.png\n",
      "00380.png\n",
      "00381.png\n",
      "00382.png\n",
      "00383.png\n",
      "00384.png\n",
      "00385.png\n",
      "00386.png\n",
      "00387.png\n",
      "00388.png\n",
      "00389.png\n",
      "00390.png\n",
      "00391.png\n",
      "00392.png\n",
      "00393.png\n",
      "00394.png\n",
      "00395.png\n",
      "00396.png\n",
      "00397.png\n",
      "00398.png\n",
      "00399.png\n",
      "00400.png\n",
      "00401.png\n",
      "00402.png\n",
      "00403.png\n",
      "00404.png\n",
      "00405.png\n",
      "00406.png\n",
      "00407.png\n",
      "00408.png\n",
      "00409.png\n",
      "00410.png\n",
      "00411.png\n",
      "00412.png\n",
      "00413.png\n",
      "00414.png\n",
      "00415.png\n",
      "00416.png\n",
      "00417.png\n",
      "00418.png\n",
      "00419.png\n",
      "00420.png\n",
      "00421.png\n",
      "00422.png\n",
      "00423.png\n",
      "00424.png\n",
      "00425.png\n",
      "00426.png\n",
      "00427.png\n",
      "00428.png\n",
      "00429.png\n",
      "00430.png\n",
      "00431.png\n",
      "00432.png\n",
      "00433.png\n",
      "00434.png\n",
      "00435.png\n",
      "00436.png\n",
      "00437.png\n",
      "00438.png\n",
      "00439.png\n",
      "00440.png\n",
      "00441.png\n",
      "00442.png\n",
      "00443.png\n",
      "00444.png\n",
      "00445.png\n",
      "00446.png\n",
      "00447.png\n",
      "00448.png\n",
      "00449.png\n",
      "00450.png\n",
      "00451.png\n",
      "00452.png\n",
      "00453.png\n",
      "00454.png\n",
      "00455.png\n",
      "00456.png\n",
      "00457.png\n",
      "00458.png\n",
      "00459.png\n",
      "00460.png\n",
      "00461.png\n",
      "00462.png\n",
      "00463.png\n",
      "00464.png\n",
      "00465.png\n",
      "00466.png\n",
      "00467.png\n",
      "00468.png\n",
      "00469.png\n",
      "00470.png\n",
      "00471.png\n",
      "00472.png\n",
      "00473.png\n",
      "00474.png\n",
      "00475.png\n",
      "00476.png\n",
      "00477.png\n",
      "00478.png\n",
      "00479.png\n",
      "00480.png\n",
      "00481.png\n",
      "00482.png\n",
      "00483.png\n",
      "00484.png\n",
      "00485.png\n",
      "00486.png\n",
      "00487.png\n",
      "00488.png\n",
      "00489.png\n",
      "00490.png\n",
      "00491.png\n",
      "00492.png\n",
      "00493.png\n",
      "00494.png\n",
      "00495.png\n",
      "00496.png\n",
      "00497.png\n",
      "00498.png\n",
      "00499.png\n",
      "log.txt\n",
      "progress.csv\n"
     ]
    }
   ],
   "source": [
    "import blobfile as bf\n",
    "import os\n",
    "for entry in sorted(os.listdir(\"myoutput/all30016/\")):\n",
    "    print(entry)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('sde')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "18f6dd5e28ea51b7c193753a74cd2f37f776e591a014247ffd6312f5124d577c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
